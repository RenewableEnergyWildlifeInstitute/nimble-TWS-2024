---
title: "Strategies for improving MCMC"
subtitle: "NIMBLE 2024 TWS Workshop"
author: "NIMBLE Development Team"
date: "October 2024"
output:
  slidy_presentation: default
  html_document:
    code_folding: show
---
<style>
slides > slide {
  overflow-x: auto !important;
  overflow-y: auto !important;
}
</style>

```{r setup, include=FALSE}
library(nimble)
library(compareMCMCs)
library(nimbleEcology)
has_rjags <- require(rjags)
if(!has_rjags)
  warning("This Rmd file uses package rjags.  Sections using it will be skipped.")
recalculate <- FALSE
makeplot <- !recalculate
```

Overview
=====

Some strategies for improving MCMC

 - Customize sampler choices. E.g.,
    - Try sampling standard deviations on a log scale
    - Try slice samplers instead of Metropolis-Hastings [already seen].
    - Try blocking correlated parameters
    - Try multiple samplers for slow-mixing parameters [not shown].
 - Reparameterize
    - Center covariates [already seen]
    - Centered versus non-centered random effects parameterization
    - Rotated coordinates to reduce posterior correlation [already seen; more here]
 - Rewrite the model. E.g.,
    - Rewrite the model to reduce dependencies [already seen]
    - Vectorize declarations to improve computational efficiency [already seen] 
    - Marginalize to remove parameters [already seen] 
 - (Advanced) Write new samplers that take advantage of particular model structures

Sampler choices 
=====

Sampler choices:

- Sampling standard deviations on the  log scale can help, especially when there is posterior support near 0.
- Slice sampling can help mix a parameter at some computational cost.
- Hamiltonian Monte Carlo (HMC) can help mix blocks of parameters (often all parameters at once) but at heavy computational cost.
- Blocking can help when parameters are correlated *given other parameters*.
    - If parameters are *marginally correlated* but *conditionally independent*, blocking will not help.
    - This occurs if parameters are marginally correlated only because they both depend on something else.
- Model-specific understanding can yield good sampling strategies.
- When we are comparing the results of using different samplers, make sure to check the the efficiency by looking at the effective sample sizes per time

Centering covariates or random effects
=====

Centering refers to two issues:

- Centering of covariates as they are provided for the analysis.
    - Think of $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$. 
    - If the $x_i$ are not centered, then considering $\beta_1 \rightarrow \beta_1'$ is also like adding $(\beta_1' - \beta_1) \bar{x}$ to the intercept.
    - A standard result in linear regression is that estimates of $\beta_0$ and $\beta_1$ are correlated.
    - Centering $x_i$ around its mean removes the posterior correlation between $\beta_0$ and $\beta_1$.

- Random effects with a mean of zero (non-centered parameterization) versus centered around a mean (centered parameterization).
    - E.g., `random_effect ~ N(0, sd)` vs. `random_effect ~ N(mean, sd)`.
    - Theory shows either parameterization can be better, depending on the model and data, but with reasonable amount of data, centered is often better.
    - However, for HMC, uncentered is generally better!

Back to the Martins
=====

```{r}
martin_code <- nimbleCode({
  # Priors and constraints
  logN.est[1] ~ dnorm(5.6, 0.01)       # Prior for initial population size
  mean.r ~ dnorm(1, 0.001)             # Prior for mean growth rate
  sigma.proc ~ dunif(0, 1)          # Prior for sd of state process
  sigma2.proc <- pow(sigma.proc, 2)
  tau.proc <- pow(sigma.proc, -2)
  sigma.obs ~ dunif(0, 1)           # Prior for sd of observation process
  sigma2.obs <- pow(sigma.obs, 2)
  tau.obs <- pow(sigma.obs, -2)
  
  # Likelihood
  # State process
  for (t in 1:(T-1)) {
    logN.est[t+1] ~ dnorm(logN.est[t] + mean.r, tau.proc)
  }
  
  # Observation process
  for (t in 1:T) {
    y[t] ~ dnorm(logN.est[t], tau.obs)
  }
  
  # Population sizes on real scale
  for (t in 1:T) {
    N.est[t] <- exp(logN.est[t])
  }
})

# Code from BPA book:
pyears <- 6 # Number of future years with predictions
hm <- c(271, 261, 309, 318, 231, 216, 208, 226, 195, 226, 233, 209, 
        226, 192, 191, 225, 245, 205, 191, 174, rep(NA, pyears))
year <- 1990:(2009 + pyears)

# Bundle data
martin_data <- list(y = log(hm), T = length(year))
## NIMBLE will handle y as data, T as a constant

# Initial values
martin_inits <- function(){
  list(sigma.proc = runif(1, 0, 1), mean.r = rnorm(1),
       sigma.obs = runif(1, 0, 1), 
       logN.est = c(rnorm(1, 5.6, 0.1), 
                    rep(NA, (length(year)-1))))
}

martin_model <- nimbleModel(martin_code,
                                constants = martin_data,
                                inits = martin_inits(), buildDerivs = TRUE)
mcmcConf <- configureMCMC(martin_model)
mcmcConf$printSamplers()
```

Modifying an MCMC configuration in `nimble`
=====

Let's replace the default RW (adaptive random-walk Metropolis-Hastings) samplers to sample on the log scale to not get stuck at small values. (Reminder! This is because truncated variables like standard deviation can get stuck near the limits.)

```{r, eval = recalculate}
pars <- c("sigma.proc", "sigma.obs")
mcmcConf$removeSamplers(pars)
pars <- martin_model$expandNodeNames(pars) # Good way to make sure that all node names are consistent
for(p in pars)
  mcmcConf$addSampler(target = p,
                      type = "RW", log=TRUE)
mcmcConf$printSamplers(pars)
mcmc <- buildMCMC(mcmcConf)
compiled <- compileNimble(martin_model, mcmc)
mcmc.out.log <- runMCMC(compiled$mcmc, niter = 30000, 
                          nchains = 3, nburnin = 10000, samplesAsCodaMCMC = TRUE)

plot(mcmc.out.log[, c('sigma.proc', 'sigma.obs')])
```

```{r, eval = recalculate, include = FALSE}
png("martin_results_with_slides/mcmc_output_log.png")
plot(mcmc.out.log[, c('sigma.proc', 'sigma.obs')])
dev.off()
```


```{r, echo = FALSE, out.width="80%"}
if(makeplot) 
  knitr::include_graphics("martin_results_with_slides/mcmc_output_log.png")
```

Modifying an MCMC configuration in `nimble`
=====

Let's replace the default RW (adaptive random-walk Metropolis-Hastings) samplers with slice samplers in the martins example. When blocking, you can end up with quicker computation, however, need to think about whether these data re on appropriate scales.

```{r, eval = recalculate}
pars <- c("sigma.proc", "sigma.obs")
mcmcConf$removeSamplers(pars)
pars <- martin_model$expandNodeNames(pars)
for(p in pars)
  mcmcConf$addSampler(target = p,
                      type = "slice") # automatically looks for nimbleFunction named "slice" or "sampler_slice"
mcmcConf$printSamplers(pars)
mcmc <- buildMCMC(mcmcConf)
compiled <- compileNimble(martin_model, mcmc)
mcmc.out.slice <- runMCMC(compiled$mcmc, niter = 30000, 
                          nchains = 3, nburnin = 10000, samplesAsCodaMCMC = TRUE)
plot(mcmc.out.slice[, c('sigma.proc', 'sigma.obs')])
```


```{r, eval = recalculate, include = FALSE}
png("martin_results_with_slides/mcmc_output_slice.png")
plot(mcmc.out.slice[, c('sigma.proc', 'sigma.obs')])
dev.off()
```

```{r, echo = FALSE, out.width="80%"}
if(makeplot) 
  knitr::include_graphics("martin_results_with_slides/mcmc_output_slice.png")
```


Modifying an MCMC configuration in `nimble`
=====

Let's replace the default RW (adaptive random-walk Metropolis-Hastings) samplers with a block sampler on the log scale.

```{r, eval = recalculate}
pars <- c("sigma.proc", "sigma.obs")
mcmcConf$removeSamplers(pars)
pars <- martin_model$expandNodeNames(pars)
mcmcConf$addSampler(target = pars,
                      type = "RW_block", log = TRUE) # automatically looks for nimbleFunction named "slice" or "sampler_slice"
mcmcConf$printSamplers(pars)
mcmc <- buildMCMC(mcmcConf)
compiled <- compileNimble(martin_model, mcmc)
mcmc.out.block <- runMCMC(compiled$mcmc, niter = 30000, 
                          nchains = 3, nburnin = 10000, samplesAsCodaMCMC = TRUE)
plot(mcmc.out.block[, c('sigma.proc', 'sigma.obs')])
```


```{r, eval = recalculate, include = FALSE}
png("martin_results_with_slides/mcmc_output_block.png")
plot(mcmc.out.block[, c('sigma.proc', 'sigma.obs')])
dev.off()
```

```{r, echo = FALSE, out.width="80%"}
if(makeplot) 
  knitr::include_graphics("martin_results_with_slides/mcmc_output_block.png")
```


Hamiltonian Monte Carlo
=====

Let's consider Hamiltonian Monte Carlo (HMC). This will use automatic differentiation to sample the parameters. TO run HMC, you need to ensure that the nimbleModel set the `buildDerivs=T`. This uses the chain rule. Also, this uses the package nimbleHMC. You can make all of the nodes HMC by using the package + buildHMC or you can build it only for certain nodes.

```{r, hmc, eval = recalculate}
library(nimbleHMC)
cmodel <- compileNimble(martin_model)
hmc <- buildHMC(martin_model)
cHMC <- compileNimble(hmc, project = martin_model)
mcmc.out.hmc <- runMCMC(cHMC, niter = 30000, 
                          nchains = 3, nburnin = 10000, samplesAsCodaMCMC = TRUE)
plot(mcmc.out.hmc[, c('sigma.proc', 'sigma.obs')])
```

```{r, eval = recalculate, include = FALSE}
png("martin_results_with_slides/mcmc_output_hmc.png")
plot(mcmc.out.hmc[, c('sigma.proc', 'sigma.obs')])
dev.off()
```


```{r, echo = FALSE, out.width="80%"}
if(makeplot) 
  knitr::include_graphics("martin_results_with_slides/mcmc_output_hmc.png")
```


Marginalization
=====

Marginalizing is doing some math to reduce the number of variables (kinda? I don't fully get it). In a hierarchical model, one can *in principle* always integrate over latent states. However only under certain situations can one do those integrals in closed form (analytically).

Analytic integration is always possible in conjugate situations. For example:

$$ y_i \sim N(\mu_i, \sigma^2); i=1,\ldots,n $$
$$ \mu_i \sim N(\mu_0, \sigma_0^2),  i=1,\ldots,n $$

Here there is one latent state per observation. We can do MCMC here, but it involves a large number of parameters, n+3.

If we marginalize:

  - We reduce the total number of computations done at each step of the MCMC.
  - We reduce the dimensionality of the parameter space needing exploration.
  - In some cases the complexity of calculating the marginalized density offsets some of the benefits above.

Here's the marginalized result, with only 3 parameters.

$$ y_i \sim N(\mu_0, \sigma^2 + \sigma_0^2) $$

Mixture Models
=====

Occupancy mixture model example from [Turek, Wehrhahn and Gimenez (2021). Bayesian non-parametric detection heterogeneity in ecological models.](https://link.springer.com/article/10.1007/s10651-021-00489-1)


```{r}
set.seed(123)
## number of sites
N <- 1000
## number of observation periods
T <- 6
## probability of occupancy
pOcc <- 0.7
## detection probability
pVec <- rep(c(0.2, 0.8), each=N/2)

## simulate z (occupied status),
## and y (encounter histories)
set.seed(0)
z <- rep(NA, N)
y <- matrix(NA, nrow=N, ncol=T)
for(i in 1:N) {
    z[i] <- rbinom(1, size=1, prob=pOcc)
    y[i, 1:T] <- rbinom(T, size=1, prob=z[i]*pVec[i])
}
```

```{r, eval = recalculate}
code <- nimbleCode({
    pOcc ~ dunif(0, 1)
    p ~ dunif(0, 1)
    for(i in 1:N) {
        y[i,1:T] ~ dOcc_s(pOcc, p, len=T)
    }
})
constants <- list(N=N, T=T)
data <- list(y=y)
inits <- list(pOcc=0.5, p=0.5)

Rmodel <- nimbleModel(code, constants, data, inits)
conf <- configureMCMC(Rmodel)
Rmcmc <- buildMCMC(conf)
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project=Rmodel)
samples <- runMCMC(Cmcmc, niter=15000, nchains=3, 
                  nburnin = 5000, samplesAsCodaMCMC = TRUE)
plot(samples[, 'p'])
```
```{r, eval = recalculate, include = FALSE}
png("martin_results_with_slides/mcmc_output_occ_basic.png")
plot(samples[, 'p'])
dev.off()
```


```{r, echo = FALSE, out.width="80%"}
if(makeplot) 
  knitr::include_graphics("martin_results_with_slides/mcmc_output_occ_basic.png")
```


Mixture Models
=====

Now let's make three different detectability probabilities that we then assign to each survey with probability `pi`.

```{r, eval = recalculate}
## 3-Group Finite Mixture Occupancy Model
code <- nimbleCode({
    pOcc ~ dunif(0, 1)
    for(k in 1:K)   p[k] ~ dunif(0, 1) # p is still being explored in the MCMC
    one[1] ~ dconstraint(p[1] <= p[2])  ## Identifiability This deals with the idea of label-switching in n-mixture modeling. Make sure the p 1 is less than p2 which is less than p3. This is a little bit of a trick because deconstraint acts as a distribution which can enforce the logic within them
    one[2] ~ dconstraint(p[2] <= p[3])
    for(i in 1:N) {
        g[i] ~ dcat(pi[1:K])
        y[i,1:T] ~ dOcc_s(pOcc, p[g[i]], len=T) #g is an indext of detection probability, there will be K different detection probabilities. 
    }
})
K <- 3    ## fixed number of groups
constants <- list(N=N, T=T, K=K)
data <- list(y=y, one=rep(1,K-1))
inits <- list(pOcc=0.5, pi=rep(1/K,K), p=rep(0.5,K), g=rep(1,N))
Rmodel <- nimbleModel(code, constants, data, inits)
conf <- configureMCMC(Rmodel, monitors = c("pi", "pOcc", "p"))
Rmcmc <- buildMCMC(conf)
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project=Rmodel)
samples.mix <- runMCMC(Cmcmc, niter=15000, nchains=3, 
                       nburnin = 5000, samplesAsCodaMCMC = TRUE)
plot(samples.mix[, c('p[1]', 'p[2]', 'p[3]')])
```
```{r, eval = recalculate, include = FALSE}
png("martin_results_with_slides/mcmc_output_occ_mix.png")
plot(samples.mix[, c('p[1]', 'p[2]', 'p[3]')])
dev.off()
```

```{r, echo = FALSE, out.width="80%"}
if(makeplot) knitr::include_graphics("martin_results_with_slides/mcmc_output_occ_mix.png")
```



Marginalization of the Mixture Model
=====

We can always integrate over finite discrete random variables by summation, so we can integrate over the `g[i]` variables, which take values of 1, 2, or 3. WE can use this to write a marginal distriburion rather than sampling all the latent nodes

```{r}
doccmix <- nimbleFunction(
  run = function(x = double(1), pOcc = double(0), 
                 pDet = double(1), wgt = double(1),
                 len = double(),
                 log = logical(0, default = 0)) {
    
    returnType(double(0))
    # generally we want to calculate probability (density) on a 
    # log scale, but here that won't work.
    dens <- 0
    for( i in seq_along(pDet)){
      dens <- dens + wgt[i]*dOcc_s(x, pOcc, pDet[i], len=len, log = FALSE)
    }
    if(log) 
      return(log(dens)) else return(dens)
  })
```

```{r, include=FALSE}
# only needed for Rmd compilation; not needed for regular usage.
assign('doccmix', doccmix, .GlobalEnv)
# 'r' simulation function not required but included here because of Rmd compilation issues.
roccmix <- nimbleFunction(
  run = function(n = integer(0), pOcc = double(0), 
                 pDet = double(1), wgt = double(1), len = double()) {
  # warning: dummy code    
  returnType(double(1))
  return(numeric(1))
})

assign('roccmix', roccmix, .GlobalEnv)
```

Using the new distribution
====

One can then immediately use the distribution in a model. NIMBLE will compile the user-defined distribution together with everything else, as if `doccmix` were a distribution that NIMBLE provides.

```{r, eval = recalculate}
## 3-Group Finite Mixture Occupancy Model - marginalized
code <- nimbleCode({
    pOcc ~ dunif(0, 1)
    for(k in 1:K)   p[k] ~ dunif(0, 1)
    one[1] ~ dconstraint(p[1] <= p[2])  ## Identifiability
    one[2] ~ dconstraint(p[2] <= p[3])
    for(i in 1:N) {
        y[i,1:T] ~ doccmix(pOcc = pOcc, pDet = p[1:K], wgt = pi[1:K], len=T)
    }
})
K <- 3    ## fixed number of groups
constants <- list(N=N, T=T, K=K)
data <- list(y=y, one=rep(1,K-1))
inits <- list(pOcc=0.5, pi=rep(1/K,K), p=rep(0.5,K), g=rep(1,N))
Rmodel <- nimbleModel(code, constants, data, inits)
conf <- configureMCMC(Rmodel, monitors = c("pi", "pOcc", "p"))
Rmcmc <- buildMCMC(conf)
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project=Rmodel)
samples.marg <- runMCMC(Cmcmc, niter=15000, nchains=3, 
                       nburnin = 5000, samplesAsCodaMCMC = TRUE)
plot(samples.marg[, c('p[1]', 'p[2]', 'p[3]')])
```

```{r, eval = recalculate, include = FALSE}
png("martin_results_with_slides/mcmc_output_occ_marg.png")
plot(samples.marg[, c('p[1]', 'p[2]', 'p[3]')])
dev.off()
```

```{r, echo = FALSE, out.width="80%"}
if(makeplot) knitr::include_graphics("martin_results_with_slides/mcmc_output_occ_marg.png")
```


Writing your own sampler (Bonus if time allows)
=====

Consider a very basic linear regression of cars data in R, where distance depends on speed. SHows that we can write our own sampler and apply it to a specific node

```{r, eval = FALSE}
## Understanding MCMC with Nimble:
code <- nimbleCode({
  ## Choose priors:
  b0 ~ dflat() # dunif(-Inf, Inf) flat prior for intercept.
  b1 ~ dnorm(0, tau = 0.1)  # vague prior for slope.
  sigma ~ dunif(0, 100) # flat prior for residual standard error. dhalfflat() also works.
  
  for (i in 1:n) {
    mu[i] <- b0 + b1 * speed[i]
    dist[i] ~ dnorm(mu[i], sd = sigma)
  }
})

inits <- list(b0 = 0, b1 = 3, sigma = 3)
constants <- list(n = nrow(cars), speed = cars$speed)

model <- nimbleModel(
  code = code,
  data = list(dist = cars$dist),
  constants = list(n = nrow(cars), speed = cars$speed),
  inits = list(
    b0 = rnorm(1),
    b1 = rnorm(1),
    sigma = rgamma(1, 1)
  )
)

cmodel  <- compileNimble(model)
## Build the MCMC
mcmc    <- buildMCMC(model, monitors = c("b0", "b1", "sigma")) ## Track key parameters
## Compile the MCMC samplers into C++
cmcmc   <- compileNimble(mcmc, project = model)

## Now run some iterations of the MCMC
cmcmc$run(1000)
samples <- as.matrix(cmcmc$mvSamples)
out <- as.mcmc(samples)

plot(out[, 'b0'])
```

Now let's write our own Metropolis Hastings sampler to provide to our MCMC.

```{r, eval = FALSE}
My_RW_sampler <- nimbleFunction(
    contains = sampler_BASE,
    setup = function(model, mvSaved, target, control) {
        scale <- control$scale
        calcNodes <- model$getDependencies(target)
    },
    run = function() {
        currentValue <- model[[target]]
        currentLogProb <- model$getLogProb(calcNodes)
        
        proposedValue <- currentValue + rnorm(1, 0, sd = scale)
        model[[target]] <<- proposedValue
        proposalLogProb <- model$calculate(calcNodes)
        
        log_accept_prob <- proposalLogProb - currentLogProb
        
        ## Equivalent to: accept <- runif(1) < exp(log_accept_prob)
        accept <- decide(log_accept_prob) 
        
        if(accept) {
            ## return new model (saved when running "calculate")
            copy(from = model, to = mvSaved, row = 1, nodes = calcNodes, logProb = TRUE)
        } else {
            ## return original model (saved before updating)
            copy(from = mvSaved, to = model, row = 1, nodes = calcNodes, logProb = TRUE)
        }    
    },
    ## Ignore this for now.
    methods = list(reset = function() {
    })    
)

## Let's add it to the MCMC
mcmcConf <- configureMCMC(model)
mcmcConf$removeSamplers('b0')
mcmcConf$addSampler(target = 'b0', type = 'My_RW_sampler', control = list(scale = 1.2))
mcmcConf$printSamplers('b0')
mcmc <- buildMCMC(mcmcConf, monitors = c("b0",  "b1", "sigma")) ## Track key parameters
cmcmc   <- compileNimble(mcmc, project = model, resetFunctions = TRUE)

## Now run some iterations of the MCMC
cmcmc$run(1000)
samples <- as.matrix(cmcmc$mvSamples)
out <- as.mcmc(samples)
plot(out[,'b0'])
```

Basic model checking with `DHARMa` and Nimble (Bonus 2 if time allows)
====

We can build a posterior predictive nimbleFunction to interact with our model which can be used to interact with `DHARMa` for simulated residual checks. Simply need. We need to be able to provide observed data, predicted response, and simulated data

- `Simulated response vectors` which are posterior predictive draws of a Bayesian model,
- `Observed data` in this case `y`
- `The predicted response from the model` in this case probability of occupancy x probability of observation.

```{r, eval = FALSE}
ppSamplerNF <- nimbleFunction(
          setup = function(model, mcmc) {
              dataNodes <- model$getNodeNames(dataOnly = TRUE)
              parentNodes <- model$getParents(dataNodes, stochOnly = TRUE)
              cat("Stochastic parents of data are:", paste(parentNodes, collapse = ','), ".\n")
              simNodes <- model$getDependencies(parentNodes, self = FALSE)
              vars <- mcmc$mvSamples$getVarNames()  # need ordering of variables in mvSamples / samples matrix
              cat("Using posterior samples of:", paste(vars, collapse = ','), ".\n")
              n <- length(model$expandNodeNames(dataNodes, returnScalarComponents = TRUE))
          },
          run = function(samples = double(2)) {
              nSamp <- dim(samples)[1]
              ppSamples <- matrix(nrow = nSamp, ncol = n)
              for(i in 1:nSamp) {
                    values(model, vars) <<- samples[i, ]
                    model$simulate(simNodes, includeData = TRUE)
                    ppSamples[i, ] <- values(model, dataNodes)
              }
              returnType(double(2))
              return(ppSamples)
          })
```

- Let's use the basic cars example again.

```{r, eval = FALSE}
## Understanding MCMC with Nimble:
code <- nimbleCode({
  ## Choose priors:
  b0 ~ dflat() # dunif(-Inf, Inf) flat prior for intercept.
  b1 ~ dnorm(0, tau = 0.1)  # vague prior for slope.
  sigma ~ dunif(0, 100) # flat prior for residual standard error. dhalfflat() also works.
  
  for( i in 1:n ) {
    mu[i] <- b0 + b1*speed[i]
    dist[i] ~ dnorm(mu[i], sd = sigma)
  }
})

inits <- list(b0 = 0, b1 = 3, sigma = 3)
constants <- list(n = nrow(cars), speed = cars$speed)

model <- nimbleModel(code = code, 
                     data = list(dist = cars$dist), 
                     constants = list(n = nrow(cars), speed = cars$speed),                      inits = list(b0 = rnorm(1), b1 = rnorm(1), sigma = rgamma(1,1)))

cmodel  <- compileNimble(model)
## Build the MCMC
mcmc    <- buildMCMC(model, monitors = c("b0",  "b1", "sigma")) ## Track key parameters
## Compile the MCMC samplers into C++
cmcmc   <- compileNimble(mcmc, project = model)

## Now run some iterations of the MCMC
cmcmc$run(10000)
samples <- as.matrix(cmcmc$mvSamples)
out <- as.mcmc(samples)[-(1:5000),] # Burn-in

ppsampler <- ppSamplerNF(model, mcmc) 
cppsampler <- compileNimble(ppsampler)            
predictions <- cppsampler$run(samples = out)

## Get mean response:
values(cmodel, c("b0", "b1", "sigma")) <- c(-16.195, 3.843, 15.920)
cmodel$calculate()
fitted <- values(cmodel, "mu")

library(DHARMa)
resids <- createDHARMa(simulatedResponse = t(predictions), 
                           observedResponse = cars$dist,
                           fittedPredictedResponse = fitted,
                           integerResponse = FALSE)
plot(resids)

## Compare with lm:
fit.lm <- lm(dist ~ speed, data = cars)
resids.fit <- simulateResiduals(fittedModel = fit.lm, plot = TRUE)

```